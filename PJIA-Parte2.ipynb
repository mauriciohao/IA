{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36aa672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Projeto: Detecção Automática de Pragas em Plantações de Café com CNN (N1)\n",
    "Disciplina: Inteligência Artificial – 7ºN CC - Noite\n",
    "Professor: Prof. Dr. Ivan Carlos Alcântara de Oliveira\n",
    "\n",
    "Integrantes:\n",
    "- [Preencha: Nome Completo] – [RA] – [email]\n",
    "- [Adicione mais linhas se necessário]\n",
    "\n",
    "Síntese do notebook:\n",
    "- Estrutura padrão do relatório N1 (título, resumo, introdução, fundamentação, problema, ética).\n",
    "- Download/organização do dataset (IP102 como base, opcional JMuBEN/JMuBEN2).\n",
    "- Análise exploratória (contagem por classe, exemplos visuais), preparação dos dados (normalização, augmentation).\n",
    "- Metodologia e resultados esperados (sem treino pesado aqui; fica para N2).\n",
    "\n",
    "Histórico de alterações:\n",
    "- 2025-09-28 – [Seu Nome] – Criação do notebook de N1 com EDA e preparação.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4520b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Professor: Prof. Dr. Ivan Carlos Alcântara de Oliveira\n",
    "\n",
    "Integrantes:\n",
    "- [Preencha: Nome Completo] – [RA] – [email]\n",
    "- [Adicione mais linhas se necessário]\n",
    "\n",
    "Síntese do notebook:\n",
    "- Estrutura padrão do relatório N1 (título, resumo, introdução, fundamentação, problema, ética).\n",
    "- Download/organização do dataset (IP102 como base, opcional JMuBEN/JMuBEN2).\n",
    "- Análise exploratória (contagem por classe, exemplos visuais), preparação dos dados (normalização, augmentation).\n",
    "- Metodologia e resultados esperados (sem treino pesado aqui; fica para N2).\n",
    "\n",
    "Histórico de alterações:\n",
    "- 2025-09-28 – [Seu Nome] – Criação do notebook de N1 com EDA e preparação.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c12a574",
   "metadata": {},
   "source": [
    "# Detecção Automática de Pragas em Plantações de Café com CNN (Parte 2 – N1)\n",
    "\n",
    "Universidade Presbiteriana Mackenzie  \n",
    "Faculdade de Computação e Informática  \n",
    "*Disciplina:* Inteligência Artificial – 7ºN CC - Noite  \n",
    "*Professor:* Prof. Dr. Ivan Carlos Alcântara de Oliveira  \n",
    "\n",
    "## 1) Título\n",
    "*Detecção Automática de Pragas em Plantações de Café Utilizando Redes Neurais Convolucionais*\n",
    "\n",
    "## 2) Integrantes (nome, e-mail, RA)\n",
    "Nome do Aluno\t               / RA             \n",
    "Eduardo Honorio Friaça\t       10408959\n",
    "\n",
    "Felipe Jiao\t                   10408852\n",
    "\n",
    "Hao Yue Zheng\t               10408948\n",
    "\n",
    "Samuel Zheng\t               10395781\n",
    "\n",
    "\n",
    "## 3) Resumo\n",
    "Este trabalho descreve a proposta e a análise exploratória de um sistema de Visão Computacional para classificação de pragas em imagens de plantações de café. Utilizamos como base o IP102 (75k imagens, 102 classes de pragas) e, opcionalmente, conjuntos específicos de café (JMuBEN/JMuBEN2). São apresentados: origem dos dados, organização e limpeza, preparo (redimensionamento, normalização, data augmentation), e uma análise de distribuição de classes. Também são detalhados os aspectos éticos e a metodologia com transfer learning (ResNet18/MobileNet), além dos resultados esperados (acurácia ≥ 70%).\n",
    "\n",
    "## 4) Introdução\n",
    "### a) Contextualização\n",
    "Pragas agrícolas geram perdas econômicas relevantes. No café, insetos como broca-do-cafeeiro e bicho-mineiro são recorrentes. A IA pode acelerar o diagnóstico.\n",
    "### b) Justificativa\n",
    "Diagnóstico manual é demorado e sujeito a erro. Classificação automática por imagens auxilia a tomada de decisão no campo.\n",
    "### c) Objetivo\n",
    "Preparar e explorar dados para um classificador de pragas em café, estabelecendo uma base reprodutível para o treino do modelo (N2).\n",
    "### d) Opção do projeto\n",
    "Opção ML/DL/VC/PLN – Visão Computacional / Deep Learning.\n",
    "\n",
    "## 5) Fundamentação Teórica (Resumida)\n",
    "CNNs extraem padrões visuais via convoluções; transfer learning permite ajustar modelos pré-treinados (ResNet18/MobileNetV2) a novas classes com poucos dados.\n",
    "\n",
    "## 6) Descrição do Problema\n",
    "Identificar automaticamente a praga presente na imagem de folha/fruto de café, apesar de variações de iluminação, foco e estágio da infestação.\n",
    "\n",
    "## 7) Aspectos Éticos e Responsabilidade\n",
    "- Uso dos dados conforme licenças; anonimização quando necessário.\n",
    "- Transparência de limitações (falsos positivos/negativos); o sistema não substitui especialistas.\n",
    "- Incentivo a manejo sustentável; evitar decisões automatizadas sem supervisão.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b94a9a",
   "metadata": {},
   "source": [
    "## 8) Dataset, Análise Exploratória e Preparação (Python)\n",
    "*Fontes principais:*  \n",
    "- *IP102*: ~75k imagens, 102 classes (cobre a exigência de ≥10k imagens).  \n",
    "- *(Opcional)* JMuBEN/JMuBEN2: 58.5k imagens de folhas de café (5 classes).  \n",
    "\n",
    "### 8.1 Instalação de dependências"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be7a76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os, zipfile, tarfile, shutil, random\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"Versões:\")\n",
    "print(\"  torch:\", torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0395ca1",
   "metadata": {},
   "source": [
    "### 8.2 Download e organização do IP102\n",
    "O bloco abaixo tenta baixar espelhos do IP102. *Caso falhe*, baixe manualmente do repositório oficial e extraia para `data_ip102/`.  \n",
    "- Repo oficial: https://github.com/xpwu95/IP102\n",
    "- Após extrair, aponte `IMAGES_DIR` para a pasta `images/` com subpastas por classe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb794833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_ROOT = Path(\"./data_ip102\")\n",
    "DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def try_download_gdown(file_name, file_id):\n",
    "    try:\n",
    "        import gdown\n",
    "    except ImportError:\n",
    "        print(\"Instale gdown se quiser baixar automático: !pip install gdown\")\n",
    "        return False\n",
    "    out = DATA_ROOT / file_name\n",
    "    if out.exists():\n",
    "        print(file_name, \"já existe.\")\n",
    "        return True\n",
    "    url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "    try:\n",
    "        print(\"Baixando:\", file_name)\n",
    "        gdown.download(url, str(out), quiet=False)\n",
    "        return out.exists()\n",
    "    except Exception as e:\n",
    "        print(\"Falha no download:\", e)\n",
    "        return False\n",
    "\n",
    "def extract_any(p):\n",
    "    p = Path(p）\n",
    "    if p.exists():\n",
    "        if p.suffix == \".zip\":\n",
    "            with zipfile.ZipFile(p, \"r\") as zf:\n",
    "                zf.extractall(DATA_ROOT)\n",
    "        elif p.suffix in [\".tar\", \".gz\", \".tgz\", \".bz2\"]:\n",
    "            with tarfile.open(p, \"r:*\") as tf:\n",
    "                tf.extractall(DATA_ROOT)\n",
    "\n",
    "attempts = [\n",
    "    (\"IP102_Images.zip\", \"1gGqf8c4c2h1R5xQX_SAMPLE_REPLACE_WITH_VALID_ID\"),\n",
    "]\n",
    "for fn, fid in attempts:\n",
    "    ok = try_download_gdown(fn, fid)\n",
    "    if ok:\n",
    "        extract_any(DATA_ROOT / fn)\n",
    "\n",
    "IMAGES_DIR = DATA_ROOT / \"images\"  \n",
    "if not IMAGES_DIR.exists():\n",
    "    print(\"ATENÇÃO: Extraia manualmente o IP102 para\", IMAGES_DIR, \"com estrutura: images/class_name/*.jpg\")\n",
    "else:\n",
    "    print(\"Pasta de imagens encontrada:\", IMAGES_DIR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f29732",
   "metadata": {},
   "source": [
    "### 8.3 Preparação (transformações) e carregamento da estrutura ImageFolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b1fd0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 2\n",
    "\n",
    "data_tfms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'eval': transforms.Compose([\n",
    "        transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n",
    "\n",
    "if IMAGES_DIR.exists():\n",
    "    full_ds = datasets.ImageFolder(IMAGES_DIR, transform=data_tfms['eval'])\n",
    "    class_to_idx = full_ds.class_to_idx\n",
    "    idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
    "    print(\"Total de imagens:\", len(full_ds))\n",
    "    print(\"Total de classes:\", len(class_to_idx))\n",
    "else:\n",
    "    full_ds = None\n",
    "    print(\"Configure IMAGES_DIR primeiro.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9205ed",
   "metadata": {},
   "source": [
    "### 8.4 Análise Exploratória: contagem por classe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9e6bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if full_ds is not None:\n",
    "    counts = {c:0 for c in class_to_idx}\n",
    "    for _, y in full_ds.samples:\n",
    "        counts[idx_to_class[y]] += 1\n",
    "    df_counts = pd.DataFrame.from_dict(counts, orient='index', columns=['count']).sort_values('count', ascending=False)\n",
    "    display(df_counts.head(20))\n",
    "    print(\"Classes com menos imagens (potencial desbalanceamento):\")\n",
    "    display(df_counts.tail(20))\n",
    "\n",
    "    # Gráfico: distribuição das top-N classes (N=20), um gráfico único sem subplots\n",
    "    topN = 20\n",
    "    df_top = df_counts.head(topN)\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.bar(df_top.index, df_top['count'])\n",
    "    plt.title(f\"Distribuição (Top {topN}) de Imagens por Classe\")\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.xlabel(\"Classe\")\n",
    "    plt.ylabel(\"Quantidade de imagens\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a12c71",
   "metadata": {},
   "source": [
    "### 8.5 Visualização de exemplos (sem subplots)\n",
    "Mostraremos algumas imagens individuais (uma por figura) para inspecionar a qualidade dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f5db705",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_n_examples_per_class(ds, max_classes=5):\n",
    "    if ds is None:\n",
    "        print(\"Dataset não carregado.\")\n",
    "        return\n",
    "    shown_classes = 0\n",
    "    seen = set()\n",
    "    for path, y in ds.samples:\n",
    "        cname = idx_to_class[y]\n",
    "        if cname in seen:\n",
    "            continue\n",
    "        seen.add(cname)\n",
    "        try:\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            plt.figure(figsize=(4,4))\n",
    "            plt.imshow(img)\n",
    "            plt.axis('off')\n",
    "            plt.title(f\"Classe: {cname}\")\n",
    "            plt.show()\n",
    "            shown_classes += 1\n",
    "            if shown_classes >= max_classes:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            continue\n",
    "\n",
    "if full_ds is not None:\n",
    "    show_n_examples_per_class(full_ds, max_classes=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b7080b",
   "metadata": {},
   "source": [
    "### 8.6 Split (treino/validação/teste)\n",
    "Divisão estratificada simples por classe (70/15/15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6d42f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import random, math\n",
    "\n",
    "if full_ds is not None:\n",
    "    samples_by_class = {}\n",
    "    for p, y in full_ds.samples:\n",
    "        cname = idx_to_class[y]\n",
    "        samples_by_class.setdefault(cname, []).append((p,y))\n",
    "\n",
    "    train_list, val_list, test_list = [], [], []\n",
    "    for cname, items in samples_by_class.items():\n",
    "        random.shuffle(items)\n",
    "        n = len(items)\n",
    "        n_train = int(0.7*n)\n",
    "        n_val = int(0.15*n)\n",
    "        train_list += items[:n_train]\n",
    "        val_list   += items[n_train:n_train+n_val]\n",
    "        test_list  += items[n_train+n_val:]\n",
    "\n",
    "    class SubsetDS(Dataset):\n",
    "        def __init__(self, samples, transform, loader):\n",
    "            self.samples = samples\n",
    "            self.transform = transform\n",
    "            self.loader = loader\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "        def __getitem__(self, i):\n",
    "            path, y = self.samples[i]\n",
    "            img = Image.open(path).convert('RGB')\n",
    "            if self.transform: \n",
    "                img = self.transform(img)\n",
    "            return img, y\n",
    "\n",
    "    ds_train = SubsetDS(train_list, data_tfms['train'], full_ds.loader)\n",
    "    ds_val   = SubsetDS(val_list,   data_tfms['eval'],  full_ds.loader)\n",
    "    ds_test  = SubsetDS(test_list,  data_tfms['eval'],  full_ds.loader)\n",
    "\n",
    "    dl_train = DataLoader(ds_train, batch_size=32, shuffle=True, num_workers=2)\n",
    "    dl_val   = DataLoader(ds_val,   batch_size=32, shuffle=False, num_workers=2)\n",
    "    dl_test  = DataLoader(ds_test,  batch_size=32, shuffle=False, num_workers=2)\n",
    "\n",
    "    print(f\"Tamanhos -> train: {len(ds_train)}, val: {len(ds_val)}, test: {len(ds_test)}\")\n",
    "else:\n",
    "    print(\"Carregue o dataset antes do split.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aef0eae",
   "metadata": {},
   "source": [
    "## 9) Metodologia e Resultados Esperados\n",
    "- *Modelo:* Transfer learning (ResNet18/MobileNetV2) com última camada ajustada para o número de classes.\n",
    "- *Treino:* Acontecerá no N2 (outro notebook focado em desenvolvimento e resultados). Nesta etapa, reportamos apenas o *plano*.\n",
    "- *Métricas esperadas:* Acurácia ≥ 70% no conjunto de teste; além disso, precisão/recall/F1 por classe e matriz de confusão.\n",
    "- *Próximos passos (N2):* Treinar, validar, ajustar hiperparâmetros, gerar relatório final, vídeo e link GitHub públicos.\n",
    "\n",
    "## 10) Referências (citar dentro do texto do relatório)\n",
    "- IP102: A Large-Scale Benchmark Dataset for Insect Pest Recognition (repositório oficial).\n",
    "- He, K. et al. Deep Residual Learning for Image Recognition (ResNet).\n",
    "- Howard, A. et al. MobileNets: Efficient Convolutional Neural Networks for Mobile Vision.\n",
    "\n",
    "## 11) Bibliografia\n",
    "- Goodfellow, Bengio, Courville – Deep Learning (MIT Press)\n",
    "- Géron – Hands-On Machine Learning (O’Reilly)\n",
    "- Bishop – Pattern Recognition and Machine Learning (Springer)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
